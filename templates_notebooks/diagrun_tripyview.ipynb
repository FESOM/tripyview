{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4475ac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# get_ipython().magic('matplotlib notebook')\n",
    "get_ipython().magic('matplotlib inline')\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "#_______________________________________________________________________________________________\n",
    "import yaml\n",
    "import pkg_resources\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "from tripyview import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672af011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data on previous runs exist in /home/ollie/pscholz/tripyview_github/Results/TRR181_TKE+IDEMIX_test/TRR181_TKE+IDEMIX_test.json, \n",
      "\n",
      "they will be used to generate output for diagnostics you do not run this time.\n"
     ]
    }
   ],
   "source": [
    "#_________________________________________________________________________________________________\n",
    "# load yaml setting file\n",
    "yaml_filename='diagrun_test.yml'\n",
    "# yaml_filename='diagrun_tke+idemix_tuning.yml'\n",
    "\n",
    "with open(yaml_filename) as file:\n",
    "    yaml_settings = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "#_________________________________________________________________________________________________    \n",
    "# name of workflow runs --> also folder name \n",
    "workflow_name = yaml_settings['workflow_name']\n",
    "\n",
    "# setup data input paths & input names\n",
    "input_paths = yaml_settings['input_paths']\n",
    "if 'input_names' in yaml_settings:\n",
    "    input_names = yaml_settings['input_names']\n",
    "else:\n",
    "    input_names = list()\n",
    "    for path in input_paths: \n",
    "        input_names.append(path.split('/')[-3])\n",
    "if len(input_names) != len(input_paths): raise ValueError(\"The size of input_names & input_paths is not equal\") \n",
    "\n",
    "# setup save path    \n",
    "if 'save_path' in yaml_settings: \n",
    "    save_path = f\"{yaml_settings['save_path']}/{workflow_name}\"\n",
    "else:\n",
    "    save_path = f\"./results/{workflow_name}\" \n",
    "save_path = os.path.expanduser(save_path)\n",
    "save_path = os.path.abspath(save_path)\n",
    "\n",
    "    \n",
    "#_________________________________________________________________________________________________    \n",
    "# actualize settings dictionary    \n",
    "yaml_settings['input_paths']       = input_paths\n",
    "yaml_settings['input_names']       = input_names\n",
    "yaml_settings['workflow_name']     = workflow_name\n",
    "yaml_settings['workflow_settings'] = None\n",
    "yaml_settings['save_path']         = save_path\n",
    "yaml_settings['save_path_nb' ]     = os.path.join(save_path, \"notebooks\")\n",
    "yaml_settings['save_path_fig']     = os.path.join(save_path, \"figures\")    \n",
    "\n",
    "#_________________________________________________________________________________________________\n",
    "# create save directory if they do not exist\n",
    "if not os.path.exists(yaml_settings['save_path']):\n",
    "    print(f' --> mkdir: {yaml_settings[\"save_path\"]}')\n",
    "    os.makedirs(yaml_settings[\"save_path\"])\n",
    "    print(f' --> mkdir: {yaml_settings[\"save_path_nb\"]}')\n",
    "    os.makedirs(yaml_settings[\"save_path_nb\"])\n",
    "    print(f' --> mkdir: {yaml_settings[\"save_path_fig\"]}')\n",
    "    os.makedirs(yaml_settings[\"save_path_fig\"])\n",
    "    \n",
    "#_________________________________________________________________________________________________    \n",
    "# initialise/create webpage interface .json file\n",
    "fname_json = f\"{yaml_settings['workflow_name']}.json\"\n",
    "save_path_json = os.path.join(yaml_settings['save_path'], fname_json)\n",
    "if os.path.exists(save_path_json):\n",
    "    with open(save_path_json) as json_file:\n",
    "        webpages = json.load(json_file)\n",
    "        print(f\"Data on previous runs exist in {save_path_json}, \\n\")\n",
    "        print(\"they will be used to generate output for diagnostics you do not run this time.\")\n",
    "else:\n",
    "    webpages = {}\n",
    "    webpages[\"analyses\"] = {}\n",
    "\n",
    "webpages[\"general\"] = {}\n",
    "webpages[\"general\"][\"name\"] = yaml_settings[\"workflow_name\"]\n",
    "\n",
    "#_________________________________________________________________________________________________\n",
    "# define analyses drivers\n",
    "analyses_opt = {}\n",
    "analyses_opt[\"hslice\"         ] = drive_hslice\n",
    "analyses_opt[\"hslice_np\"      ] = drive_hslice\n",
    "analyses_opt[\"hslice_sp\"      ] = drive_hslice\n",
    "analyses_opt[\"hslice_clim\"    ] = drive_hslice_clim\n",
    "analyses_opt[\"hovm\"           ] = drive_hovm\n",
    "analyses_opt[\"hovm_clim\"      ] = drive_hovm_clim\n",
    "analyses_opt[\"xmoc\"           ] = drive_xmoc\n",
    "analyses_opt[\"vprofile\"       ] = drive_vprofile\n",
    "analyses_opt[\"vprofile_clim\"  ] = drive_vprofile_clim\n",
    "analyses_opt[\"transect\"       ] = drive_transect\n",
    "analyses_opt[\"transect_clim\"  ] = drive_transect_clim\n",
    "analyses_opt[\"zmeantrans\"     ] = drive_zmeantrans\n",
    "analyses_opt[\"zmeantrans_clim\"] = drive_zmeantrans_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7dcbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Black is not installed, parameters wont be formatted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> compute hslice:\n",
      " --> drive_hslice: hslice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ddccd5befc42538e7f2303d05848b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Black is not installed, parameters wont be formatted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c6957662814be28f0f25323c9a2313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#_________________________________________________________________________________________________\n",
    "# loop over all analyses\n",
    "for analysis in analyses_opt:\n",
    "    # check if analysis is in input yaml settings\n",
    "    if analysis in yaml_settings:\n",
    "        print(f\" --> compute {analysis}:\")\n",
    "        # drive specific analysis\n",
    "        webpage = analyses_opt[analysis](yaml_settings, analysis)\n",
    "        webpages[\"analyses\"][analysis] = webpage\n",
    "        \n",
    "        # write linked analysis to .json file\n",
    "        with open(save_path_json, \"w\") as fp: json.dump(webpages, fp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e17c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_________________________________________________________________________________________________            \n",
    "# save everything to .html\n",
    "fname_html     = f\"{yaml_settings['workflow_name']}.html\"\n",
    "save_path_html = os.path.join(yaml_settings['save_path'], fname_html)\n",
    "ofile          = open(save_path_html, \"w\")\n",
    "template       = env.get_template(\"experiment.html\")\n",
    "output         = template.render(webpages)\n",
    "ofile.write(output)\n",
    "ofile.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db48602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_________________________________________________________________________________________________            \n",
    "# render page\n",
    "# render_main_page()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
