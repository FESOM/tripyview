{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/albedo/home/pscholz/tripyview\n"
     ]
    }
   ],
   "source": [
    "# get_ipython().magic('matplotlib notebook')\n",
    "# get_ipython().magic('matplotlib inline')\n",
    "# get_ipython().magic('load_ext autoreload')\n",
    "# get_ipython().magic('autoreload 2')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "#___________________________________________________________________________________________________________________\n",
    "import os\n",
    "import tripyview as tpv\n",
    "import shapefile as shp\n",
    "import numpy     as np\n",
    "import xarray    as xr\n",
    "import time      as clock\n",
    "import warnings\n",
    "xr.set_options(keep_attrs=True)\n",
    "do_parallel   = True\n",
    "parallel_nprc = 48   # number of dask workers\n",
    "parallel_tmem = 200  # max. available RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFO:\n",
    "To compute especially on large unstructured grids #vertices>1M, you need to run this notebook in parallel (do_parallel=True) on several workers (parallel_nprc...is the number of dask worker that can be allocated, parallel_tmem...is the maximum available RAM that will be distributed between the dask workers). Therefor allocate a full !!! COMPUTE NODE !!! (admins might not be happy if you do this in parallel on a login node) of a HPC of your choice with as much memory (RAM) as you can get to run this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> memory_limit: 4.167 GB\n"
     ]
    }
   ],
   "source": [
    "if do_parallel:\n",
    "    from dask.distributed import Client\n",
    "    # from dask.diagnostics import ProgressBar\n",
    "    import dask\n",
    "    print(' --> memory_limit: {:3.3f} GB'.format(parallel_tmem/(parallel_nprc)))\n",
    "    ## dask.config.config.get('distributed').get('dashboard').update({'link':'{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'})\n",
    "    client = Client(n_workers=parallel_nprc, threads_per_worker=1, memory_limit='{:3.3f} GB'.format(parallel_tmem/parallel_nprc))\n",
    "    client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# mesh_path ='/work/ollie/projects/clidyn/FESOM2/meshes/core2/'\n",
    "mesh_path = '/albedo/work/user/pscholz/mesh_fesom2.0/core2_srt_dep@node/'\n",
    "# mesh_path = '/albedo/work/user/pscholz/mesh_fesom2.0/dart_test/'\n",
    "save_path = None \n",
    "save_fname= None\n",
    "\n",
    "#_____________________________________________________________________________________\n",
    "which_cycl= None #5 # set None --> take path as in input_paths otherwise add dir of cycle\n",
    "which_mode= 'hovm'\n",
    "\n",
    "input_paths= list()\n",
    "input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke+idemix_jayne_bin_ck0.1/5/')\n",
    "input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke+idemix_nycander_bin_ck0.1/')\n",
    "input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke+idemix_stormtide_bin_ck0.1/')\n",
    "input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke_ctrl_ck0.1/5/')\n",
    "# input_paths.append('/albedo/work/user/pscholz/results/dart_linfs_pc0_ctrl_1/1/')\n",
    "\n",
    "\n",
    "input_names= list()\n",
    "input_names.append('TKE+IDEMIX, jayne')\n",
    "input_names.append('TKE+IDEMIX, nycander')\n",
    "input_names.append('TKE+IDEMIX, stormtide')\n",
    "input_names.append('TKE')\n",
    "\n",
    "vname     = 'temp'\n",
    "year      = [1958, 2019]\n",
    "mon, day, record, box, depth = None, None, None, None, None\n",
    "\n",
    "#_____________________________________________________________________________________\n",
    "# do anomaly plots in case ref_path is not None\n",
    "# ref_path  = None #'/home/ollie/pscholz/results/trr181_tke_ctrl_ck0.1/' # None\n",
    "# ref_name  = None #'TKE, ck=0.1' # None\n",
    "# ref_year  = None # [2009,2019]\n",
    "# ref_mon, ref_day, ref_record = None, None, None\n",
    "\n",
    "#_____________________________________________________________________________________\n",
    "box_region = list()\n",
    "box_region.append('global')\n",
    "# box_region.append('ocean_basins/Arctic_Basin.shp')\n",
    "# box_region.append('ocean_basins/Eurasian_Basin.shp')\n",
    "# box_region.append('mpas_region/Canada_Basin.shp')\n",
    "# box_region.append('mpas_region/North_Atlantic_Ocean.shp')\n",
    "# box_region.append('mpas_region/Greenland_Sea.shp')\n",
    "# box_region.append('mpas_region/Irminger_Sea.shp')\n",
    "# box_region.append('mpas_region/Norwegian_Sea.shp')\n",
    "# box_region.append('mpas_region/Labrador_Sea.shp')\n",
    "# box_region.append('mpas_region/North_Pacific_Ocean.shp')\n",
    "# box_region.append('mpas_region/South_Pacific_Ocean.shp')\n",
    "# box_region.append('mpas_region/Southern_Ocean.shp')\n",
    "# box_region.append('mpas_region/Western_Weddell_Sea.shp')\n",
    "\n",
    "#_____________________________________________________________________________________\n",
    "which_clim= 'phc3'\n",
    "clim_path = '/albedo/work/projects/p_fesom/FROM-OLLIE/FESOM2/hydrography/phc3.0/phc3.0_annual.nc'\n",
    "\n",
    "#_____________________________________________________________________________________\n",
    "cstr, cnum  = 'blue2red', 15\n",
    "cref, crange, cmin, cmax, cfac, climit = 0, None, None, None, None, None\n",
    "chist, ctresh = True, 0.995\n",
    "\n",
    "ref_cstr, ref_cnum = 'wbgyr', 15\n",
    "ref_cref, ref_crange, ref_cmin, ref_cmax, ref_cfac, ref_climit = None, None, None, None, None, None\n",
    "ref_chist, ref_ctresh = True, 0.995\n",
    "\n",
    "#_____________________________________________________________________________________\n",
    "ncol              = 2        # number of pannel columns in figure\n",
    "do_plt            = 'tcf'\n",
    "do_rescale        = None\n",
    "do_lsm            ='fesom' # 'fesom', 'bluemarble', 'etopo', 'stock'\n",
    "do_mesh, mesh_opt = True, dict({'color':'k', 'linewidth':0.10})\n",
    "do_enum           = False\n",
    "do_reffig         = True\n",
    "ax_title          = None\n",
    "cb_label          = None\n",
    "save_dpi          = 300\n",
    "save_fmt          = ['png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > found *.pckl file: /albedo/work/user/pscholz/mesh_fesom2.0/core2_srt_dep@node\n",
      " > load  *.pckl file: tripyview_fesom2_core2_srt_dep@node_focus0.pckl\n",
      "___FESOM2 MESH INFO________________________\n",
      " > path            = /albedo/work/user/pscholz/mesh_fesom2.0/core2_srt_dep@node\n",
      " > id              = core2_srt_dep@node\n",
      " > do rot          = None\n",
      " > [al,be,ga]      = 50, 15, -90\n",
      " > do augmpbnd     = True\n",
      " > do cavity       = False\n",
      " > do lsmask       = True\n",
      " > do earea,eresol = True, False\n",
      " > do narea,nresol = True, False\n",
      "___________________________________________\n",
      " > #node           = 126858\n",
      " > #elem           = 244659\n",
      " > #lvls           = 48\n",
      "___________________________________________\n"
     ]
    }
   ],
   "source": [
    "#___LOAD FESOM2 MESH___________________________________________________________________________________\n",
    "mesh=tpv.load_mesh_fesom2(mesh_path, do_rot='None', focus=0, do_info=True, do_pickle=True)\n",
    "\n",
    "#______________________________________________________________________________________________________\n",
    "if (which_cycl != None) and (which_cycl != \"None\"): \n",
    "    for ii,ipath in enumerate(input_paths):\n",
    "        input_paths[ii] = os.path.join(ipath,'{:d}/'.format(which_cycl))\n",
    "        print(ii, input_paths[ii])\n",
    "    \n",
    "#     if (ref_path != None) and (ref_path != \"None\"): \n",
    "#         ref_path = os.path.join(ref_path,'{:d}/'.format(which_cycl))\n",
    "#         print('R', ref_path)\n",
    "        \n",
    "#______________________________________________________________________________________________________        \n",
    "cinfo=tpv.set_cinfo(cstr, cnum, crange, cmin, cmax, cref, cfac, climit, chist, ctresh)\n",
    "ref_cinfo=None\n",
    "if do_reffig:     \n",
    "#     if ref_year   is None: ref_year   = year\n",
    "#     if ref_mon    is None: ref_mon    = mon\n",
    "#     if ref_record is None: ref_record = record\n",
    "    ref_cinfo=tpv.set_cinfo(ref_cstr, ref_cnum, ref_crange, ref_cmin, ref_cmax, ref_cref, ref_cfac, ref_climit, ref_chist, ref_ctresh)\n",
    "    \n",
    "# #______________________________________________________________________________________________________    \n",
    "# # concatenate list = list1+list2\n",
    "# if (ref_path != None): \n",
    "#     if isinstance(ref_path, list): \n",
    "#         input_paths, input_names = ref_path + input_paths        , ref_name + input_names \n",
    "#     else:    \n",
    "#         input_paths, input_names = list([ref_path]) + input_paths, list([ref_name]) + input_names\n",
    "        \n",
    "#______________________________________________________________________________________________________\n",
    "# define index regions --> reading shape files\n",
    "box = list()\n",
    "shp_path = os.path.join(tpv.__path__[0], 'shapefiles/')\n",
    "for region in box_region:\n",
    "    if region == 'global' or isinstance(region,list): box.append(region)\n",
    "    else: box.append(shp.Reader(os.path.join(shp_path, region)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m ts \u001b[38;5;241m=\u001b[39m clock\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m clim      \u001b[38;5;241m=\u001b[39m tpv\u001b[38;5;241m.\u001b[39mload_climatology(mesh, clim_path, clim_vname, do_load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, do_persist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mSTOP\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --> elasped time to load clim: \u001b[39m\u001b[38;5;132;01m{:3.2f}\u001b[39;00m\u001b[38;5;124m min.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat( (clock\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mts)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m  ))        \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --> clim uses \u001b[39m\u001b[38;5;132;01m{:3.2f}\u001b[39;00m\u001b[38;5;124m Gb:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(clim\u001b[38;5;241m.\u001b[39mnbytes\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "data_list  = list()\n",
    "\n",
    "#___LOAD CLIMATOLOGY___________________________________________________________________________________\n",
    "clim_vname = vname\n",
    "if (vname in ['temp', 'salt', 'pdens'] or 'sigma' in vname): \n",
    "    # load climatology and interpolate to fesom grid \n",
    "    if   vname=='temp' and  which_clim.lower()=='woa18': clim_vname = 't00an1'\n",
    "    elif vname=='salt' and  which_clim.lower()=='woa18': clim_vname = 's00an1'\n",
    "    ts = clock.time()\n",
    "    clim      = tpv.load_climatology(mesh, clim_path, clim_vname, do_load=False, do_persist=True)\n",
    "    \n",
    "    STOP\n",
    "    print(' --> elasped time to load clim: {:3.2f} min.'.format( (clock.time()-ts)/60  ))        \n",
    "    print(' --> clim uses {:3.2f} Gb:'.format(clim.nbytes/(1024**3)))\n",
    "    \n",
    "    # create hovmoeller from clim\n",
    "    ts = clock.time()\n",
    "    clim_hovm = tpv.load_index_fesom2(mesh, clim, box, do_harithm='wmean')\n",
    "    print(' --> elasped time to comp. clim hovm.: {:3.2f} min.'.format( (clock.time()-ts)/60  ))   \n",
    "    for ii, data_ii in enumerate(clim_hovm):\n",
    "        print(' --> clim_hovm[{:s}] uses {:3.2f} Mb:'.format(clim_hovm[ii][list(clim_hovm[ii].keys())[0]].attrs['boxname'], clim_hovm[ii].nbytes/(1024**2)))\n",
    "    \n",
    "    if do_reffig: data_list.append(clim_hovm)\n",
    "    del(clim)\n",
    "    print('')\n",
    "else: raise ValueError('climatology not supported for choosen vname')    \n",
    "\n",
    "#___LOAD FESOM2 DATA___________________________________________________________________________________\n",
    "for datapath, descript in zip(input_paths, input_names):\n",
    "    print(datapath)\n",
    "    ts = clock.time()\n",
    "    #__________________________________________________________________________________________________\n",
    "    # load fesom2 data\n",
    "    data  = tpv.load_data_fesom2(mesh, datapath, vname=vname, year=year, mon=mon,  descript=descript, \n",
    "                                do_tarithm='None', do_zarithm='None', do_info=False, do_load=False, do_persist=True )\n",
    "    print(' --> elasped time to load data: {:3.2f} min.'.format( (clock.time()-ts)/60  ))        \n",
    "    print(' --> data uses {:3.2f} Gb:'.format(data.nbytes/(1024**3)))\n",
    "    \n",
    "    #__________________________________________________________________________________________________    \n",
    "    # check if data where loaded\n",
    "    if data is None: raise ValueError(f'data == None, data could not be readed, your path:{datapath} might be wrong!!!')\n",
    "    \n",
    "    #__________________________________________________________________________________________________\n",
    "    # create hovmoeller from data\n",
    "    ts = clock.time()\n",
    "    data_hovm = tpv.load_index_fesom2(mesh, data, box, do_harithm='wmean')\n",
    "    del(data)\n",
    "\n",
    "    # compute anomalous hovmoeller with respect to climatology\n",
    "    data_hovm = tpv.do_indexanomaly(data_hovm, clim_hovm)\n",
    "    print(' --> elasped time to comp. data hovm.: {:3.2f} min.'.format( (clock.time()-ts)/60  ))   \n",
    "    for ii, data_ii in enumerate(data_hovm):\n",
    "        print(' --> data_hovm[{:s}] uses {:3.2f} Mb:'.format(data_hovm[ii][list(data_hovm[ii].keys())[0]].attrs['boxname'], data_hovm[ii].nbytes/(1024**2)))\n",
    "    data_list.append(data_hovm)\n",
    "    del(data_hovm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#___PLOT HOVM__________________________________________________________________________________________\n",
    "spath  = save_path\n",
    "ncol0  = np.min([ncol,len(data_list)])    \n",
    "nrow0  = np.ceil(len(data_list)/ncol0).astype('int')\n",
    "nbox, ndat = len(box), len(data_list)\n",
    "for box_idx in range(nbox):\n",
    "    svname = list(data_list[-1][box_idx].data_vars)[0]\n",
    "    slabel = data_list[-1][box_idx][svname].attrs['str_lsave']\n",
    "    sbox   = data_list[-1][box_idx][svname].attrs['boxname'].replace(' ','_').lower()\n",
    "    #__________________________________________________________________________________________________\n",
    "    # do save filename path\n",
    "    sfpath = None\n",
    "    if spath!=None: \n",
    "        sfpath=list()\n",
    "        for sfmt in save_fmt: sfpath.append( os.path.join(spath,'{:s}_{:s}_{:s}_{:s}.{:s}'.format(svname, 'hovmclim', sbox ,slabel, sfmt)) )\n",
    "       \n",
    "    #__________________________________________________________________________________________________\n",
    "    # do colorbar either single cbar or ref_cbar + anom_cbar\n",
    "    if do_reffig: cb_plt, cb_plt_single, cinfo0 = [1]+[2]*(ndat-1), False, [ref_cinfo.copy(), cinfo.copy()]\n",
    "    else: cb_plt, cb_plt_single, cinfo0 = True, True, cinfo.copy() \n",
    "        \n",
    "    #__________________________________________________________________________________________________    \n",
    "    hfig, hax, hcb = tpv.plot_vslice(mesh, data_list, nrow=nrow0, ncol=ncol0, box_idx=box_idx, \n",
    "                                     cinfo=cinfo0, \n",
    "                                     do_plt=do_plt, plt_contb=False, plt_contf=True, plt_contr=False, plt_contl=True, do_enum=do_enum, \n",
    "                                     ax_opt=dict({'fig_sizefac':2.0, 'cb_plt':cb_plt, 'cb_plt_single':cb_plt_single, 'cb_pos':'vertical', 'cb_h':'auto',}), # 'fs_label':14, 'fs_ticks':14, 'ax_dt':1.0}),\n",
    "                                     cbl_opt=dict(), cb_label=cb_label, cbtl_opt=dict(),\n",
    "                                     do_save=sfpath )    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
