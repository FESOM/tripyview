{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/a270275/tripyview/tripyview/sub_data.py:8: UserWarning: The seawater library is deprecated! Please use gsw instead.\n",
      "  import seawater as sw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/a/a270275/tripyview\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#___________________________________________________________________________________________________________________\n",
    "import os\n",
    "import tripyview as tpv\n",
    "import numpy     as np\n",
    "import xarray    as xr\n",
    "import time      as clock\n",
    "import shapefile as shp\n",
    "import warnings\n",
    "xr.set_options(keep_attrs=True)\n",
    "client_runs   = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFO:\n",
    "To compute especially on large unstructured grids #vertices>1M, you need to run this notebook in parallel (do_parallel=True) on several workers (parallel_nprc...is the number of dask worker that can be allocated, parallel_tmem...is the maximum available RAM that will be distributed between the dask workers). Therefor allocate a full !!! COMPUTE NODE !!! (admins might not be happy if you do this in parallel on a login node) of a HPC of your choice with as much memory (RAM) as you can get to run this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "#___Dask Client Parameters____________________________________________________________\n",
    "do_papermill      = False\n",
    "do_parallel       = False\n",
    "parallel_tnprc    = 128                          # total number of available CPUs\n",
    "parallel_nprc     = 72                           # number of dask workers\n",
    "parallel_nprc_bin = parallel_tnprc-parallel_nprc # number of processor used to parallize the binning loop\n",
    "parallel_tmem     = 200       \n",
    "\n",
    "#___Mesh Path & Save Path_____________________________________________________________\n",
    "# mesh_path ='/work/ollie/projects/clidyn/FESOM2/meshes/core2/'\n",
    "mesh_path     ='/work/ab0246/a270092/input/fesom2/core2/'\n",
    "#'/albedo/work/user/pscholz/mesh_fesom2.0/core2_srt_dep@node/'\n",
    "save_path     = None #'~/figures/test_papermill/'\n",
    "save_fname    = None # filename from papermill come in through save_fname\n",
    "tripyrun_name      = None # papermill workflow name of notebook \n",
    "tripyrun_analysis  = None # papermill diagnostic driver\n",
    "tripyrun_spath_nb  = None # papermill path to processed notebooks\n",
    "tripyrun_spath_fig = None # papermill path to processed figures\n",
    "\n",
    "#___Data Path & Input Names___________________________________________________________\n",
    "input_paths   = list()\n",
    "input_paths.append('/work/ab0995/a270275/experiments/5Ymulti_diag/outdata/fesom/')\n",
    "#input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke+idemix_jayne_bin_ck0.1/5/')\n",
    "#input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke+idemix_nycander_bin_ck0.1/5/')\n",
    "#input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke+idemix_stormtide_bin_ck0.1/5/')\n",
    "#input_paths.append('/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke_ctrl_ck0.1/5/')\n",
    "\n",
    "input_names   = list()\n",
    "input_names.append('TKE+IDEMIX, jayne')\n",
    "input_names.append('TKE+IDEMIX, nycander')\n",
    "input_names.append('TKE+IDEMIX, stormtide')\n",
    "input_names.append('TKE')\n",
    "\n",
    "\n",
    "# n_cycl: which spinupcycle should be plottet if do_allcycl all spinupcycles from [1...n_cycle] are plottet, if None path is directly used\n",
    "n_cycl    = None\n",
    "do_allcycl= True \n",
    "vname     = 'temp'\n",
    "year      = [1960, 1964]\n",
    "mon       = None\n",
    "day       = None\n",
    "record    = None \n",
    "box       = None\n",
    "depth     = None\n",
    "\n",
    "#___Define Reference Data, Year, Mon ...______________________________________________\n",
    "# do anomaly plots in case ref_path is not None\n",
    "ref_path  = None # '/albedo/work/projects/p_fesom/pscholz/project_TRR181/trr181_tke_ctrl_ck0.1/5/'\n",
    "ref_name  = None # 'TKE'\n",
    "ref_year  = None #[1979, 2019]\n",
    "ref_mon   = None\n",
    "ref_day   = None\n",
    "ref_record= None\n",
    "\n",
    "#___Define Boxregion via shape file for index compuation______________________________\n",
    "box_region = list()\n",
    "box_region.append('global')\n",
    "# box_region.append('ocean_basins/Arctic_Basin.shp')\n",
    "# box_region.append('ocean_basins/Eurasian_Basin.shp')\n",
    "# box_region.append('mpas_region/Canada_Basin.shp')\n",
    "# box_region.append('mpas_region/North_Atlantic_Ocean.shp')\n",
    "# box_region.append('mpas_region/Greenland_Sea.shp')\n",
    "# box_region.append('mpas_region/Irminger_Sea.shp')\n",
    "# box_region.append('mpas_region/Norwegian_Sea.shp')\n",
    "# box_region.append('mpas_region/Labrador_Sea.shp')\n",
    "# box_region.append('mpas_region/North_Pacific_Ocean.shp')\n",
    "# box_region.append('mpas_region/South_Pacific_Ocean.shp')\n",
    "# box_region.append('mpas_region/Southern_Ocean.shp')\n",
    "# box_region.append('mpas_region/Western_Weddell_Sea.shp')\n",
    "\n",
    "#___Define Climatology________________________________________________________________\n",
    "which_clim= 'phc3'\n",
    "clim_path = '/albedo/work/projects/p_fesom/FROM-OLLIE/FESOM2/hydrography/phc3.0/phc3.0_annual.nc'\n",
    "\n",
    "#___Define Colormap Parameters________________________________________________________\n",
    "# papermill doesnt like multi variable alignment in a single line\n",
    "cstr      = 'blue2red'\n",
    "cnum      = 15\n",
    "cref      = None\n",
    "crange    = None\n",
    "cmin      = None\n",
    "cmax      = None\n",
    "cfac      = None\n",
    "climit    = None\n",
    "chist     = True\n",
    "ctresh    = 0.995\n",
    "\n",
    "ref_cstr  = 'wbgyr'\n",
    "ref_cnum  = 15\n",
    "ref_cref  = None\n",
    "ref_crange= None\n",
    "ref_cmin  = None\n",
    "ref_cmax  = None\n",
    "ref_cfac  = None\n",
    "ref_climit= None\n",
    "ref_chist = True\n",
    "ref_ctresh= 0.995\n",
    "\n",
    "#___Define Plot Parameters____________________________________________________________\n",
    "ncol              = 1      # number of pannel columns in figure\n",
    "nrow              = 1\n",
    "plt_opt           = dict({'marker':'o'})\n",
    "do_concat         = False \n",
    "do_enum           = False  # do enumeration of panels\n",
    "do_shdw           = False\n",
    "do_mean           = True\n",
    "do_std            = False\n",
    "save_dpi          = 300\n",
    "save_fmt          = ['png']\n",
    "which_tmean       = 'None' # 'None', 'annual', 'monthly'\n",
    "which_hzmean      = 'wmean'\n",
    "\n",
    "# these parameters are not needed here but need to be defined for papermill \n",
    "box               = [-180, 180, -90, 90]\n",
    "do_plt            = 'tcf'  # plot pcolor (tpc) or contourf (tcf)\n",
    "plt_contb         = False   # background contour line (thin)\n",
    "plt_contf         = False  # contour line of main colorbar steps \n",
    "plt_contr         = False  # contour line of reference value \n",
    "plt_contl         = False  # label contourline of main colorbar steps \n",
    "do_rescale        = None   # rescale data: None, 'log10', 'slog10', np.array(...)\n",
    "do_lsm            ='fesom' # 'fesom', 'bluemarble', 'etopo', 'stock'\n",
    "do_mesh           = False, \n",
    "mesh_opt          = dict({'color':'k', 'linewidth':0.10})\n",
    "do_reffig         = False   # plot reference fig when doing anomalies \n",
    "do_clim           = False   # plot climatolgy values when doing absoluts\n",
    "ax_title          = None\n",
    "cb_label          = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start parallel dask client\n",
    "if do_parallel and not client_runs:\n",
    "    from dask.distributed import Client\n",
    "    ##import dask\n",
    "    ## dask.config.config.get('distributed').get('dashboard').update({'link':'{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'})\n",
    "    print(' --> memory_limit: {:3.3f} GB'.format(parallel_tmem/(parallel_nprc)))\n",
    "    client = Client(n_workers=parallel_nprc, threads_per_worker=1, memory_limit='{:3.3f} GB'.format(parallel_tmem/parallel_nprc))\n",
    "    client_runs = True\n",
    "    client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > warning: pickle5 module could not be found, no do_pickle \n",
      " is possible! Therefor switch to joblib saving/loading\n",
      " > found *.jlib file: /work/ab0246/a270092/input/fesom2/core2\n",
      " > load  *.jlib file: tripyview_fesom2_core2_focus0.jlib\n",
      "___FESOM2 MESH INFO________________________\n",
      " > path            = /work/ab0246/a270092/input/fesom2/core2\n",
      " > id              = core2\n",
      " > do rot          = None\n",
      " > [al,be,ga]      = 50, 15, -90\n",
      " > do augmpbnd     = True\n",
      " > do cavity       = False\n",
      " > do lsmask       = True\n",
      " > do earea,eresol = True, False\n",
      " > do narea,nresol = True, False\n",
      "___________________________________________\n",
      " > #node           = 126858\n",
      " > #elem           = 244659\n",
      " > #lvls           = 48\n",
      "___________________________________________\n",
      "global\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/a270275/.conda/envs/py39/lib/python3.9/pickle.py:1717: UserWarning: Unpickling a shapely <2.0 geometry object. Please save the pickle again; shapely 2.1 will not have this compatibility.\n",
      "  setstate(state)\n"
     ]
    }
   ],
   "source": [
    "#___LOAD FESOM2 MESH___________________________________________________________________________________\n",
    "mesh=tpv.load_mesh_fesom2(mesh_path, do_rot='None', focus=0, do_info=True, do_pickle=True)\n",
    "\n",
    "#__________________________________________________________________________________________________   \n",
    "if n_cycl is not None: \n",
    "    cycl_s=1 if do_allcycl else n_cycl\n",
    "    aux_path, aux_name = list(), list()\n",
    "    input_paths_old, input_names_old = input_paths, input_names\n",
    "    for ii, (ipath,iname) in enumerate(zip(input_paths,input_names)):\n",
    "        for ii_cycl in range(cycl_s, n_cycl+1):\n",
    "            # input_paths[ii] = os.path.join(ipath,'{:d}/'.format(which_cycl))\n",
    "            aux_path.append(os.path.join(ipath,'{:d}/'.format(ii_cycl)))\n",
    "            if not do_allcycl: aux_name.append('{}'.format(iname))\n",
    "            else             : aux_name.append('{:d}) {}'.format(ii_cycl, iname))\n",
    "            print(ii, aux_path[-1],aux_name[-1])\n",
    "    input_paths, input_names = aux_path, aux_name\n",
    "    \n",
    "    #__________________________________________________________________________________________________\n",
    "    if (ref_path is not None): \n",
    "        cycl_s=1 if do_allcycl else n_cycl\n",
    "        aux_path, aux_name = list(), list()\n",
    "        ref_path_old, ref_name_old = ref_path, ref_name\n",
    "        for ii_cycl in range(cycl_s, n_cycl+1):\n",
    "            #ref_path = os.path.join(ref_path,'{:d}/'.format(which_cycl))\n",
    "            aux_path.append(os.path.join(ref_path,'{:d}/'.format(ii_cycl)))\n",
    "            if not do_allcycl: aux_name.append('{}'.format(ref_name))\n",
    "            else             : aux_name.append('{:d}) {}'.format(ii_cycl, ref_name))\n",
    "            print('R', ref_path[-1])        \n",
    "        ref_path, ref_name = aux_path, aux_name\n",
    "    del(aux_path, aux_name)    \n",
    "        \n",
    "#______________________________________________________________________________________________________        \n",
    "cinfo=tpv.set_cinfo(cstr, cnum, crange, cmin, cmax, cref, cfac, climit, chist, ctresh)\n",
    "    \n",
    "#______________________________________________________________________________________________________\n",
    "# in case of diff plots\n",
    "if (ref_path is not None): \n",
    "    if ref_year   is None: ref_year   = year\n",
    "    if ref_mon    is None: ref_mon    = mon\n",
    "    if ref_record is None: ref_record = record\n",
    "\n",
    "#______________________________________________________________________________________________________    \n",
    "# concatenate list = list1+list2\n",
    "if (ref_path is not None): \n",
    "    if isinstance(ref_path, list): \n",
    "        input_paths, input_names = ref_path + input_paths        , ref_name + input_names\n",
    "    else:    \n",
    "        input_paths, input_names = list([ref_path]) + input_paths, list([ref_name]) + input_names        \n",
    "        \n",
    "#________________________________________________________________________________________________________\n",
    "# define index regions --> reading shape files\n",
    "box = list()\n",
    "shp_path = os.path.join(tpv.__path__[0],'shapefiles/')\n",
    "for region in box_region:\n",
    "    if region == 'global' or isinstance(region,list): \n",
    "        print('global')\n",
    "        box.append(region)\n",
    "    else: \n",
    "        print(tpv.__path__[0],region)\n",
    "        box.append(shp.Reader(os.path.join(shp_path,region)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /work/ab0995/a270275/experiments/5Ymulti_diag/outdata/fesom/ TKE+IDEMIX, jayne\n",
      " --> elasped time to load data: 0.02 min.\n",
      " --> data uses 0.13 Gb:\n"
     ]
    }
   ],
   "source": [
    "#___LOAD FESOM2 DATA___________________________________________________________________________________\n",
    "data_list  = list()\n",
    "for ii, (datapath, descript) in enumerate(zip(input_paths, input_names)):\n",
    "    print(ii, datapath, descript)\n",
    "    ts = clock.time()\n",
    "    #__________________________________________________________________________________________________\n",
    "    # load data and do vertical weighted mean \n",
    "    data = tpv.load_data_fesom2(mesh, datapath, vname=vname, year=year, mon=mon, descript=descript, \n",
    "                                do_tarithm=which_tmean, do_zarithm='None', do_zweight=True, do_info=False,\n",
    "                                do_load=False, do_persist=True, do_parallel=do_parallel)\n",
    "    #__________________________________________________________________________________________________    \n",
    "    # check if data where loaded\n",
    "    if data is None: raise ValueError(f'data == None, data could not be readed, your path:{datapath} might be wrong!!!')\n",
    "    print(' --> elasped time to load data: {:3.2f} min.'.format( (clock.time()-ts)/60  ))        \n",
    "    print(' --> data uses {:3.2f} Gb:'.format(data.nbytes/(1024**3)))\n",
    "\n",
    "    #__________________________________________________________________________________________________\n",
    "    # select horizontal index region --> do horizontal weighted mean \n",
    "    ts = clock.time()\n",
    "    data = tpv.load_index_fesom2(mesh, data, box, do_harithm=which_hzmean, do_zarithm=which_hzmean)\n",
    "    print(' --> elasped time to comp. index.: {:3.2f} min.'.format( (clock.time()-ts)/60  )) \n",
    "    \n",
    "    #__________________________________________________________________________________________________\n",
    "    # compute year mean\n",
    "    if   which_tmean=='annual':\n",
    "        data[0] = data[0].groupby('time.year').mean('time', keep_attrs=True)\n",
    "    # compute month mon --> seasonal cycle     \n",
    "    elif which_tmean=='monthly':\n",
    "        data[0] = data[0].groupby('time.month').mean('time', keep_attrs=True)\n",
    "    data_list.append(data)\n",
    "    del(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbox, ndat = len(box), len(data_list)\n",
    "if   ncol != None: \n",
    "    ncol0  = np.min([ncol, nbox])    \n",
    "    nrow0  = np.ceil(nbox/ncol0).astype('int')\n",
    "    if nrow != None: nrow0=nrow \n",
    "elif nrow != None: \n",
    "    nrow0  = np.min([nrow, nbox])    \n",
    "    ncol0  = np.ceil(nbox/nrow0).astype('int')\n",
    "\n",
    "for box_idx in range(nbox):\n",
    "    \n",
    "    #___PLOT TRANSECT__________________________________________________________________________________\n",
    "    svname = list(data_list[0][box_idx].data_vars)[0]\n",
    "    slabel = data_list[0][box_idx][svname].attrs['str_lsave']\n",
    "    stname = data_list[0][box_idx][svname].attrs['boxname'].replace(' ','_').lower()\n",
    "    #__________________________________________________________________________________________________\n",
    "    # do save filename path\n",
    "    spath  = save_path\n",
    "    sfpath = None\n",
    "    if spath!=None: \n",
    "        sfpath=list()\n",
    "        for sfmt in save_fmt: sfpath.append( os.path.join(spath,'{:s}_{:s}_{:s}_{:s}.{:s}'.format(svname, 't', stname ,slabel, sfmt)) )\n",
    "    if save_fname!=None: sfpath = [save_fname] # --> needed for diagrun papermille functionality\n",
    "\n",
    "    #__________________________________________________________________________________________________\n",
    "    fig,ax=tpv.plot_tline(data_list, box, box_idx=box_idx, \n",
    "                            nrow=nrow0, ncol=ncol0 , \n",
    "                            n_cycl     = n_cycl                  , \n",
    "                            do_allcycl = do_allcycl              , \n",
    "                            do_concat  = do_concat               , \n",
    "                            do_shdw    = do_shdw                 ,\n",
    "                            do_mean    = do_mean                 ,\n",
    "                            do_std     = do_std                  ,\n",
    "                            ax_opt     = dict({'fig_sizefac':4}) ,\n",
    "                            do_enum    = do_enum                 ,\n",
    "                            do_save    = sfpath, save_dpi=save_dpi, \n",
    "                            )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_papermill and do_parallel and client_runs:\n",
    "    client.shutdown()\n",
    "    client_runs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
